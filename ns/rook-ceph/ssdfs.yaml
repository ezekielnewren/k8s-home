apiVersion: ceph.rook.io/v1
kind: CephFilesystem
metadata:
  name: ssdfs
  namespace: rook-ceph
spec:
  metadataPool:
    replicated:
      size: 3
    parameters:
      pg_num: "128"
      pgp_num: "128"
    crushRoot: default
    failureDomain: host
    deviceClass: ssd
  dataPools:
    - name: replicated
      replicated:
        size: 3
      parameters:
        pg_num: "128"
        pgp_num: "128"
      crushRoot: default
      failureDomain: host
      deviceClass: ssd
  preserveFilesystemOnDelete: true
  metadataServer:
    activeCount: 1
    activeStandby: true
    placement:
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
        operator: Exists
      - effect: NoExecute
        key: node-role.kubernetes.io/etcd
        operator: Exists
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-ssdfs
  annotations:
    storageclass.kubernetes.io/is-default-class: "true"
provisioner: rook-ceph.cephfs.csi.ceph.com
parameters:
  clusterID: rook-ceph
  fsName: ssdfs
  pool: ssdfs-replicated
  rootPath: /csi

  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph
reclaimPolicy: Delete
allowVolumeExpansion: true

